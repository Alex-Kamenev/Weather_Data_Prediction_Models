{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b63b7c1",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3336057d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (model.py, line 1)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[0;32m~\\anaconda3\\envs\\eda\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3251\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[1;36m  Input \u001b[1;32mIn [1]\u001b[1;36m in \u001b[1;35m<module>\u001b[1;36m\u001b[0m\n\u001b[1;33m    import model_predict_py.model as model\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mC:\\Spring_2022\\Python\\Final_Project\\model_predict_py\\model.py:1\u001b[1;36m\u001b[0m\n\u001b[1;33m    %load_ext autoreload\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import edapy.datainfo as d_info\n",
    "import edapy.load_data as d_load\n",
    "import model_predict_py.model as model\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5c8312",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0df5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in data \n",
    "weather_df = d_load.load_df(r'data\\clean_weather_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96829ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate custom package class for eda \n",
    "data = d_info.DataInfo(weather_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5053a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate class for models\n",
    "md = model.Modelpredict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1899ce",
   "metadata": {},
   "source": [
    "# Check Data for inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c4e86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094977f3",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229f74f5",
   "metadata": {},
   "source": [
    "This was covered in midterm project when the team performed EDA. It may still be possible to add features that show a relationship between other features. Example: from displacement and time we can get velocity.\n",
    "\n",
    "Note to team: If anyone can thing off a feature to add please bring up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b030dc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE', 'TMAX'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6983d3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = md.one_hot_encode(df, 'COUNTY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae156b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8013c",
   "metadata": {},
   "source": [
    "# Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917be187",
   "metadata": {},
   "source": [
    "while we do have separate method to do this it is better to use a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f3106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized = md.standardize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5cbe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63167cae",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbd1d38",
   "metadata": {},
   "source": [
    "while we do have separate method to do this it is better to use a pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0893448e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized = md.normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e12a64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cadca89",
   "metadata": {},
   "source": [
    "cycle per model\n",
    "<!--  -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239e1f48",
   "metadata": {},
   "source": [
    "# Train and test split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c9d3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = md.split(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf6385a",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911ad0aa",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2321a3c1",
   "metadata": {},
   "source": [
    "### Avarage Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2350f684",
   "metadata": {},
   "source": [
    "#### with TMAX and TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5bf532",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.linear_reg(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e046d1e4",
   "metadata": {},
   "source": [
    "### with TMAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29929538",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE', 'TMIN'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.linear_reg(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd1ca6",
   "metadata": {},
   "source": [
    "### with TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28345522",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE', 'TMAX'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.linear_reg(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6355ed4b",
   "metadata": {},
   "source": [
    "### without TMAX and TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6035a458",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE', 'TMAX', 'TMIN'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.linear_reg(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e41fd",
   "metadata": {},
   "source": [
    "### Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4755c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.linear_reg(df, 'PRCP', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513694f9",
   "metadata": {},
   "source": [
    "## Random Forest Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3578e8",
   "metadata": {},
   "source": [
    "### Avarage Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e792583",
   "metadata": {},
   "source": [
    "#### with TMAX and TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d3c450",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.random_forest(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ec21c6",
   "metadata": {},
   "source": [
    "#### without TMAX and TMIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaf94ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE', 'TMAX', 'TMIN'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.random_forest(df, 'TAVG', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf353a4f",
   "metadata": {},
   "source": [
    "###  Precipitation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863a2c47",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# exctract df with feature for prediction\n",
    "df = data.drop(weather_df, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'DATE'])\n",
    "df = md.one_hot_encode(df, 'COUNTY')\n",
    "\n",
    "# build model, fit and predict\n",
    "Y_pred, Y_test = md.random_forest(df, 'PRCP', 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb90a74",
   "metadata": {},
   "source": [
    "# Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea5b8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.model_selection import grid_search_forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572045cc",
   "metadata": {},
   "source": [
    "### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get unique values in STATION feature \n",
    "list_of_stations = data.get_unique('STATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f662cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of dataframes split based on STATION name \n",
    "df_list_station = data.get_list_dfs(list_of_stations, 'STATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db568260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the head of all dfs\n",
    "for df in df_list_station:\n",
    "    display(df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179c3afb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# take one statrion to work with\n",
    "df_buffalo = df_list_station[0]\n",
    "df_buffalo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6028dde5",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086e0a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trip the df\n",
    "data = data.drop(df_buffalo, ['STATION', 'id', 'SUM_TAVG', 'NAME', 'YEAR', 'MONTH', 'DAY', 'DAYS_SINCE_JAN_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a62caf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# pop the column \n",
    "first_column = data.pop('DATE')\n",
    "\n",
    "# insert at first position \n",
    "data.insert(0, 'DATE', first_column)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b85da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "\n",
    "# Convert to datetime\n",
    "data['DATE'] = pd.to_datetime(data['DATE'], format='%Y/%m/%d')\n",
    "\n",
    "# Set as index\n",
    "data = data.set_index('DATE')\n",
    "\n",
    "# Convert TimeSeries to specified frequency\n",
    "data = data.asfreq('D')\n",
    "\n",
    "# sort\n",
    "data = data.sort_index()\n",
    "\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a206c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checked if missing values have appeared\n",
    "print(f'Number of rows with missing values: {data.isnull().any(axis=1).mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c39cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that a temporary index is complete\n",
    "\n",
    "(data.index == pd.date_range(start=data.index.min(), end=data.index.max(), freq=data.index.freq)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e230f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train-test\n",
    "\n",
    "steps = 366\n",
    "data_train = data[:-steps]\n",
    "data_test  = data[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(20, 10))\n",
    "data_train['TAVG'].plot(ax=ax, label='train')\n",
    "data_test['TAVG'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ff93e",
   "metadata": {},
   "source": [
    "## ForecasterAutoreg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ed80b5",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91fbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster\n",
    "\n",
    "forecaster_naive = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags = 366\n",
    "                )\n",
    "\n",
    "forecaster_naive.fit(y=data_train['TAVG'])\n",
    "forecaster_naive"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b5fcf8",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "steps = 366\n",
    "predictions_naive = forecaster_naive.predict(steps=steps)\n",
    "predictions_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a83fe6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "md.plot_outcome(data_train, data_test, predictions_naive, 'TAVG', 366)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ae7a0b",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4617f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hyperparameter Grid search\n",
    "\n",
    "steps = 366\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 12 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [10, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = {'n_estimators': [ 600, 800, 1000],\n",
    "              'max_depth': [30, 40, 50],\n",
    "              'bootstrap': [True, False],\n",
    "              'min_samples_leaf': [1],\n",
    "              'min_samples_split': [2],\n",
    "             }\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data_train['TAVG'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = False\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364871a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search results\n",
    "\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8d7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "\n",
    "predictions = forecaster.predict(steps = steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f8d8fd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Results of prediction \n",
    "\n",
    "md.ts_plot_outcome(data_train, data_test, predictions, 'TAVG', 366)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69bef81",
   "metadata": {},
   "source": [
    "### Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5525647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f7df59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebbab19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ff1c01f",
   "metadata": {},
   "source": [
    "# Conclusion and Future work "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa96223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
